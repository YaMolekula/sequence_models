{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767\n",
    "DEBUG = True\n",
    "\n",
    "import re, random, math, csv, io, string, itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hp = dict(\n",
    "    n_layers = 2,\n",
    "    hidden_size = 512,\n",
    "    fc_size = 512,\n",
    "    dropout = 0.9,\n",
    "    batch_size = 20,\n",
    "    lr = 0.001,\n",
    "    lr_decay = 0.9999,\n",
    "    min_lr = 0.00001,\n",
    "    grad_clip = 5.,\n",
    "    cuda = False,\n",
    "    num_epoch = 5,\n",
    "    max_length = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Voc:\n",
    "    SOS = \"!\"\n",
    "    EOS = \"#\"\n",
    "    SOS_ID = 0\n",
    "    EOS_ID = 1\n",
    "    def __init__(self):\n",
    "        self.word2index = {self.SOS:0, self.EOS:1}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0:self.SOS, 1:self.EOS}\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "\n",
    "    def index_words(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "def string2indicies(voc, text):\n",
    "    return [voc.word2index[c] for c in text]\n",
    "    \n",
    "def indicies2string(voc, indicies):\n",
    "    return \"\".join([voc.index2word[i] for i in indicies])\n",
    "\n",
    "voc = Voc()\n",
    "\n",
    "for c in itertools.chain(range(ord('a'), ord('z')+1),range(ord('A'),ord('Z')+1),(ord(\" \"),)):\n",
    "    voc.index_word(chr(c))\n",
    "# print(f'vocabulary size: {voc.n_words}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PairGenerator:\n",
    "#     vocabulary = [chr(i) for i in itertools.chain(range(ord('a'), ord('z')+1),range(ord('A'),ord('Z')+1))]\n",
    "    word_len_interval = {\"a\":2,\"b\":7}\n",
    "    sent_len_interval = {\"a\":1,\"b\":10}\n",
    "    \n",
    "    def __init__(self,voc):\n",
    "        self.voc = voc\n",
    "        self.vocabulary = [c for c in voc.word2index.keys() if c not in {voc.SOS, voc.EOS}]\n",
    "        \n",
    "    def gen_word_pair(self):\n",
    "        word_len = int(random.uniform(**self.word_len_interval))\n",
    "#         word = random.choices(self.vocabulary,k=word_len)\n",
    "        word = np.random.choice(self.vocabulary,word_len)\n",
    "        return \"\".join(word), \"\".join(list(reversed(word)))\n",
    "    \n",
    "    def gen_pair(self):\n",
    "        num_words = int(random.uniform(**self.sent_len_interval))\n",
    "        inp, out = zip(*[self.gen_word_pair() for _ in range(num_words)])\n",
    "        return self.voc.SOS+\" \".join(inp)+self.voc.EOS, self.voc.SOS+\" \".join(out)+self.voc.EOS\n",
    "    \n",
    "    def gen_batch(self, n_unrollings):\n",
    "        inp, out = zip(*[self.gen_pair() for _ in range(n_unrollings)])\n",
    "        return inp, out\n",
    "        \n",
    "pg = PairGenerator(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voc.index_words(\"!HKepmc#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['c', 'T', 'I'], dtype='<U1')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(pg.vocabulary,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,Y = pg.gen_batch(n_unrollings=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GRU:\n",
    "    hp = dict(\n",
    "        state_sz=5,\n",
    "        n_classes=2,\n",
    "        input_dim=2,\n",
    "        ckpt_path=\"./checkpoints/\"\n",
    "    )\n",
    "    def __init__(self, **hyper_parameters):\n",
    "        if hyper_parameters is not None:\n",
    "            for k, v in hyper_parameters.items():\n",
    "                self.hp[k] = v\n",
    "        self.__graph__()\n",
    "    \n",
    "    def _init(self):\n",
    "        x = tf.placeholder(tf.int32, [None, None], \"x\") #batch*voc\n",
    "        y = tf.placeholder(tf.int32, [None, None], \"y\") #batch*voc\n",
    "        emb = tf.placeholder(tf.int32, [None, None],)\n",
    "        \n",
    "        # batch_sz*seq_len -> batch_sz*seq_ln*voc_sz\n",
    "        embs = tf.get_variable('emb', [num_classes, state_size]) \n",
    "        rnn_inputs = tf.nn.embedding_lookup(embs, x)\n",
    "        \n",
    "        #batch*state_sz\n",
    "        init_state = tf.placeholder(tf.int32, [None, self.hp['state_sz']], \"init_state\")\n",
    "    \n",
    "    def _weights():\n",
    "        self.wz = tf.get_variable(\n",
    "            \"w[z]\", shape=[self.hp['state_sz'], self.hp['state_sz']],\n",
    "            initializer=tf.contrib.layers.xavier_initializer()\n",
    "        )\n",
    "        self.uz = tf.get_variable(\n",
    "            \"u[z]\", shape=[self.hp['state_sz'], self.hp['state_sz']],\n",
    "            initializer=tf.contrib.layers.xavier_initializer()\n",
    "        )\n",
    "        self.bz = tf.get_variable(\n",
    "            \"b[z]\", shape=[self.hp['state_sz']],\n",
    "            initializer=tf.constant_initializer(0.)\n",
    "        )\n",
    "        \n",
    "        self.wr = tf.get_variable(\n",
    "            \"w[r]\",  shape=[self.hp['state_sz'], self.hp['state_sz']],\n",
    "            initializer=tf.contrib.layers.xavier_initializer()\n",
    "        )\n",
    "        self.ur = tf.get_variable(\n",
    "            \"u[r]\",  shape=[self.hp['state_sz'], self.hp['state_sz']],\n",
    "            initializer=tf.contrib.layers.xavier_initializer()\n",
    "        )\n",
    "        self.br = tf.get_variable(\n",
    "            \"b[r]\", shape=[self.hp['state_sz']],\n",
    "            initializer=tf.constant_initializer(0.)\n",
    "        )\n",
    "        \n",
    "        self.wh = tf.get_variable(\n",
    "            \"w[h]\",  shape=[self.hp['state_sz'], self.hp['state_sz']],\n",
    "            initializer=tf.contrib.layers.xavier_initializer()\n",
    "        )\n",
    "        self.uh = tf.get_variable(\n",
    "            \"w[h]\",  shape=[self.hp['state_sz'], self.hp['state_sz']],\n",
    "            initializer=tf.contrib.layers.xavier_initializer()\n",
    "        )\n",
    "        self.bh = tf.get_variable(\n",
    "            \"b[h]\", shape=[self.hp['state_sz']],\n",
    "            initializer=tf.constant_initializer(0.)\n",
    "        )\n",
    "        \n",
    "        # layer to decode results of GRU \n",
    "        self.wo= tf.get_variable(\n",
    "            'w[out]', shape=[self.hp['state_sz'], self.hp['n_classes']], \n",
    "            initializer=tf.contrib.layers.xavier_initializer()\n",
    "        )\n",
    "        self.bo = tf.get_variable(\n",
    "            'b[out]', shape=[self.hp['num_classes']], \n",
    "            initializer=tf.constant_initializer(0.)\n",
    "        )\n",
    "    \n",
    "    def __graph__(self):\n",
    "        # time cycle step\n",
    "        def step(prev_state, x):\n",
    "            z = tf.matmul(x,self.wz) + tf.matmul(prev, self.uz) + self.bz\n",
    "            r = tf.matmul(x,self.wr) + tf.matmul(prev, self.ur) + self.br\n",
    "            h = tf.matmul(x,self.wh) + tf.matmul(h*prev, self.uh) + self.bh\n",
    "            return (1-z)*prev + z*h\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        self.init()\n",
    "        self.weights()\n",
    "        states = tf.scan(\n",
    "            step,\n",
    "            #batch_sz*seq_ln*voc_sz -> seq_len*batch_sz*voc_sz\n",
    "            tf.transpose(self.rnn_inputs,[1,0,2]),\n",
    "            initializer=self.init_state\n",
    "        )\n",
    "        # seq_len*batch_sz*voc_sz -> batch_sz*seq_ln*voc_sz\n",
    "        states = tf.transpose(states,[1,0,2])\n",
    "        \n",
    "        states_reshaped = tf.reshape(states, [-1, state_size])\n",
    "        logits = tf.matmul(states_reshaped, self.wo) + self.bo\n",
    "        \n",
    "        self.last_state = states[-1]\n",
    "        self.predictions = tf.nn.softmax(logits)\n",
    "        self.loss = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(logits,self.y)\n",
    "        )\n",
    "        self.train_op = tf.train.AdagradOptimizer(learning_rate=0.2).minimize(self.loss)\n",
    "        \n",
    "    def train(self,x_tarin, y_train,n_epochs = 10):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            train_loss = 0\n",
    "            try:\n",
    "                for epoch_num in range(n_epochs):\n",
    "                    pass\n",
    "            except KeyboardInterrupt as ex:\n",
    "                print(\"Interrupted by user at\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 23, 3, 12, 10, 18, 1]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string2indicies(voc, X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len_ls = list(map(len,X))\n",
    "\n",
    "mx = max(len_ls)\n",
    "diff = list(map(lambda x: mx - x, len_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 10, 12, 44, 0, 10, 32, 2, 44, 19]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.word2index[' ']*xdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!vbkiq#'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicies2string(voc, [0, 23, 3, 12, 10, 18, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
